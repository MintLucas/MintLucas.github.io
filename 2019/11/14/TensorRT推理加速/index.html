<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">



  <link rel="icon" type="image/png" sizes="32x32" href="/images/Face_ID_32px.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/Face_ID_16px.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">


  <link rel="manifest" href="/images/manifest.json">




  <meta name="keywords" content="tensorflow,">





  <link rel="alternate" href="/atom.xml" title="ZHIPENG个人笔记" type="application/atom+xml">






<meta name="description" content="TensorRT的使用 定义预处理和后处理函数如下：  冻结图 导入Keras模型，将变量转换为常量并删除用于模型训练的节点。 get_freeze_session()：返回冻结图形。   TF引擎 init()： 初始化，以设置TF图的会话。 infer()： 推理，即对一个输入图像进行推理并得到结果。 show_graph()： 显示图形，即使用第三方库在notebook中显示TensorBo">
<meta name="keywords" content="tensorflow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorRT推理加速">
<meta property="og:url" content="http://yoursite.com/2019/11/14/TensorRT推理加速/index.html">
<meta property="og:site_name" content="ZHIPENG个人笔记">
<meta property="og:description" content="TensorRT的使用 定义预处理和后处理函数如下：  冻结图 导入Keras模型，将变量转换为常量并删除用于模型训练的节点。 get_freeze_session()：返回冻结图形。   TF引擎 init()： 初始化，以设置TF图的会话。 infer()： 推理，即对一个输入图像进行推理并得到结果。 show_graph()： 显示图形，即使用第三方库在notebook中显示TensorBo">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ec2-18-224-60-97.us-east-2.compute.amazonaws.com/oqj2Fs2x/notebooks/tasks/task3/task/images/work3.png">
<meta property="og:updated_time" content="2019-11-14T03:09:28.579Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorRT推理加速">
<meta name="twitter:description" content="TensorRT的使用 定义预处理和后处理函数如下：  冻结图 导入Keras模型，将变量转换为常量并删除用于模型训练的节点。 get_freeze_session()：返回冻结图形。   TF引擎 init()： 初始化，以设置TF图的会话。 infer()： 推理，即对一个输入图像进行推理并得到结果。 show_graph()： 显示图形，即使用第三方库在notebook中显示TensorBo">
<meta name="twitter:image" content="http://ec2-18-224-60-97.us-east-2.compute.amazonaws.com/oqj2Fs2x/notebooks/tasks/task3/task/images/work3.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/11/14/TensorRT推理加速/">





  <title>TensorRT推理加速 | ZHIPENG个人笔记</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZHIPENG个人笔记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Wisdom and beauty form a very rare combination.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-首页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于-& 留言">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于 & 留言
          </a>
        </li>
      
        
        <li class="menu-item menu-item-大计划">
          <a href="/plan/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-street-view"></i> <br>
            
            大计划
          </a>
        </li>
      
        
        <li class="menu-item menu-item-阁楼">
          <a href="/loft/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-hotel"></i> <br>
            
            阁楼
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/14/TensorRT推理加速/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZHIPENG">
      <meta itemprop="description" content>
      <meta itemprop="image" content="http://p3.ssl.cdn.btime.com/t015dde82f1bf46f58d.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZHIPENG个人笔记">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">TensorRT推理加速</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-11-14T11:00:48+08:00">
                2019-11-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AiSpeech/" itemprop="url" rel="index">
                    <span itemprop="name">AiSpeech</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="TensorRT的使用"><a href="#TensorRT的使用" class="headerlink" title="TensorRT的使用"></a>TensorRT的使用</h3><p><img src="http://ec2-18-224-60-97.us-east-2.compute.amazonaws.com/oqj2Fs2x/notebooks/tasks/task3/task/images/work3.png" alt="work3"></p>
<p>定义预处理和后处理函数如下：</p>
<ul>
<li>冻结图<ul>
<li>导入Keras模型，将变量转换为常量并删除用于模型训练的节点。</li>
<li>get_freeze_session()：返回冻结图形。</li>
</ul>
</li>
<li>TF引擎<ul>
<li>init()： 初始化，以设置TF图的会话。</li>
<li>infer()： 推理，即对一个输入图像进行推理并得到结果。</li>
<li>show_graph()： 显示图形，即使用第三方库在notebook中显示TensorBoard，以可视化计算图的节点。</li>
<li>time_graphdef()：对推理速度的性能进行基准测试，返回 <strong>个图像每秒</strong> 推理基准测试。</li>
</ul>
</li>
<li>TF-TRT引擎<ul>
<li>init()： 初始化设置TF graph会话。</li>
<li>infer()： 推理，即对一个输入图像进行推理并得到结果。</li>
<li>show_graph()： 显示图形，即使用第三方库在notebook中显示TensorBoard，以可视化计算图的节点。</li>
<li>save_engine()： 保存引擎，即把TensorRT优化的引擎序列化并保存到磁盘。</li>
<li>time_graphdef()：对推理速度的性能进行基准测试，返回 <strong>个图像/秒</strong> 个推理基准测试。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FrozenGraph</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model, shape)</span>:</span></span><br><span class="line">        shape = (<span class="keyword">None</span>, shape[<span class="number">0</span>], shape[<span class="number">1</span>], shape[<span class="number">2</span>])</span><br><span class="line">        x_name = <span class="string">'image_tensor_x'</span></span><br><span class="line">        <span class="keyword">with</span> K.get_session() <span class="keyword">as</span> sess:</span><br><span class="line">          	<span class="comment">#只需要入口输入和结尾输出的名字</span></span><br><span class="line">            x_tensor = tf.placeholder(tf.float32, shape, x_name)</span><br><span class="line">            K.set_learning_phase(<span class="number">0</span>)<span class="comment">#删除用于训练节点之前必须</span></span><br><span class="line">            y_tensor = model(x_tensor)</span><br><span class="line">            y_name = y_tensor.name[:<span class="number">-2</span>]</span><br><span class="line">            graph = sess.graph.as_graph_def()</span><br><span class="line">            <span class="comment">#将权重变量都转化成常量储存</span></span><br><span class="line">            graph0 = tf.graph_util.convert_variables_to_constants(sess, graph, [y_name])</span><br><span class="line">            <span class="comment">#删除用于训练的节点</span></span><br><span class="line">            graph1 = tf.graph_util.remove_training_nodes(graph0)</span><br><span class="line"></span><br><span class="line">        self.x_name = [x_name]</span><br><span class="line">        self.y_name = [y_name]</span><br><span class="line">        self.frozen = graph1 </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_freeze_session</span><span class="params">(self, keep_var_names=None, output_names=None, clear_devices=True)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.frozen</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TfEngine</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, graph,batch_size)</span>:</span></span><br><span class="line">        g = tf.Graph()</span><br><span class="line">        <span class="keyword">with</span> g.as_default():</span><br><span class="line">            x_op, y_op = tf.import_graph_def(</span><br><span class="line">              graph_def=graph.frozen, return_elements=graph.x_name + graph.y_name)</span><br><span class="line">            print(<span class="string">"graph.x_name + graph.y_name : "</span>, graph.x_name , <span class="string">"   +   "</span>,graph.y_name)</span><br><span class="line">            self.x_tensor = x_op.outputs[<span class="number">0</span>]</span><br><span class="line">            self.y_tensor = y_op.outputs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        config = tf.ConfigProto(gpu_options=</span><br><span class="line">            tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">0.2</span>,</span><br><span class="line">            allow_growth=<span class="keyword">True</span>))</span><br><span class="line"></span><br><span class="line">        self.sess = tf.Session(graph=g, config=config)</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">infer</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y = self.sess.run(self.y_tensor,</span><br><span class="line">            feed_dict=&#123;self.x_tensor: x&#125;)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_graph</span><span class="params">(self)</span>:</span>    </span><br><span class="line">        <span class="comment"># Show current session graph with TensorBoard in Jupyter Notebook.</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> show_graph(tf.get_default_graph().as_graph_def())</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">time_graphdef</span><span class="params">(self, input_data, iteration_time)</span>:</span></span><br><span class="line">      <span class="comment"># we can now import trt_graph into Tensorflow and execute it. If given target</span></span><br><span class="line">        <span class="keyword">with</span> self.sess <span class="keyword">as</span> sess:</span><br><span class="line">            times = []</span><br><span class="line">            <span class="comment"># do a few dummy iterations to let things warm up</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">                val = sess.run(self.y_tensor, &#123;self.x_tensor: input_data&#125;)</span><br><span class="line">                </span><br><span class="line">            print(<span class="string">"start per second inference benchmark "</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(iteration_time):</span><br><span class="line">                start = time.time()</span><br><span class="line">                val = sess.run(self.y_tensor, &#123;self.x_tensor: input_data&#125;)</span><br><span class="line">                times.append(time.time() - start)</span><br><span class="line">                <span class="keyword">if</span> (i%<span class="number">100</span> ==<span class="number">0</span>): </span><br><span class="line">                    </span><br><span class="line">                    imgs_per = (<span class="number">1</span>/times[i]) * self.batch_size</span><br><span class="line">                    print(<span class="string">"Iteration  %8.2f  / %8.2f    inference speed  %5.2f  imgs/sec,   Sec/batch time: %8.5f "</span> %(i , iteration_time, imgs_per, times[i]))</span><br><span class="line">            </span><br><span class="line">            print(<span class="string">"start per second inference benchmark "</span>)</span><br><span class="line">            imgs_per = (<span class="number">1</span>/np.mean(times)) * self.batch_size</span><br><span class="line"></span><br><span class="line">                    </span><br><span class="line">            print(<span class="string">"Benchmark inference the TFTRT Engine :  %8.2f  imgs/sec"</span> % (imgs_per))</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> times</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TftrtEngine</span><span class="params">(TfEngine)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, graph, batch_size, precision)</span>:</span></span><br><span class="line">        tftrt_graph = tftrt.create_inference_graph(</span><br><span class="line">          graph.frozen, <span class="comment"># This parameter is the GraphDef object that contains the model to be transformed.</span></span><br><span class="line">          outputs=graph.y_name, <span class="comment"># This parameter lists the output nodes in the graph. Tensors which are not marked as outputs are considered to be transient values that may be optimized away by the builder.</span></span><br><span class="line">          max_batch_size=batch_size, <span class="comment">#This parameter is the maximum batch size that specifies the batch size for which TensorRT will optimize. At runtime, a smaller batch size may be chosen. At runtime, larger batch size is not supported.</span></span><br><span class="line">          max_workspace_size_bytes=<span class="number">1</span> &lt;&lt; <span class="number">25</span>, <span class="comment">#TensorRT operators often require temporary workspace. This parameter limits the maximum size that any layer in the network can use. If insufficient scratch is provided, it is possible that TensorRT may not be able to find an implementation for a given layer.</span></span><br><span class="line">          precision_mode=precision, <span class="comment">#This parameter sets the precision mode; which can be one of fp32, fp16, or int8.</span></span><br><span class="line">          minimum_segment_size=<span class="number">50</span>   <span class="comment">#This parameter determines the minimum number of TensorFlow nodes in a TensorRT engine, which means the TensorFlow subgraphs that have fewer nodes than this number will not be converted to TensorRT. Therefore, in general smaller numbers such as 5 are preferred. This can also be used to change the minimum number of nodes in the optimized INT8 engines to change the final optimized graph to fine tune result accuracy.</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.opt_graph = copy.deepcopy(graph)</span><br><span class="line">        self.opt_graph.frozen = tftrt_graph</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        super(TftrtEngine, self).__init__(self.opt_graph,self.batch_size)</span><br><span class="line">        </span><br><span class="line">        tf.reset_default_graph()</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># We can verify that we can access the list of operations in the graph</span></span><br><span class="line">        <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> graph:</span><br><span class="line">            tf.import_graph_def(tftrt_graph, name=<span class="string">""</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations():</span><br><span class="line">                print(op.name)     <span class="comment"># &lt;--- printing the operations snapshot below</span></span><br><span class="line">            <span class="comment"># prefix/Placeholder/inputs_placeholder</span></span><br><span class="line">            <span class="comment"># ...</span></span><br><span class="line">            <span class="comment"># prefix/Accuracy/predictions</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">infer</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        num_tests = x.shape[<span class="number">0</span>]</span><br><span class="line">        y = np.empty((num_tests, self.y_tensor.shape[<span class="number">1</span>]), np.float32)</span><br><span class="line">        batch_size = self.batch_size</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, num_tests, batch_size):</span><br><span class="line">            x_part = x[i : i + batch_size]</span><br><span class="line">            y_part = self.sess.run(self.y_tensor,</span><br><span class="line">                feed_dict=&#123;self.x_tensor: x_part&#125;)</span><br><span class="line">            y[i : i + batch_size] = y_part</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_engine</span><span class="params">(self,output_file_name)</span>:</span></span><br><span class="line">        print(<span class="string">'Number of nodes after conversion: &#123;&#125;'</span>.format(len(self.opt_graph.frozen.node)))</span><br><span class="line">        <span class="keyword">with</span> tf.gfile.GFile(output_file_name, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(self.opt_graph.frozen.SerializeToString())</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_graph</span><span class="params">(self)</span>:</span>    </span><br><span class="line">        <span class="comment"># Show current session graph with TensorBoard in Jupyter Notebook.</span></span><br><span class="line">        ops.reset_default_graph()</span><br><span class="line">        <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> graph:</span><br><span class="line">            tf.import_graph_def(self.opt_graph.frozen, name=<span class="string">""</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> op <span class="keyword">in</span> graph.get_operations():</span><br><span class="line">                print(op.name)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">time_graphdef</span><span class="params">(self, input_data,iteration_time)</span>:</span></span><br><span class="line">      <span class="comment"># we can now import trt_graph into Tensorflow and execute it. If given target</span></span><br><span class="line">        <span class="keyword">with</span> self.sess <span class="keyword">as</span> sess:</span><br><span class="line">            times = []</span><br><span class="line">            <span class="comment"># do a few dummy iterations to let things warm up</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">                val = sess.run(self.y_tensor, &#123;self.x_tensor: input_data&#125;)</span><br><span class="line"></span><br><span class="line">            print(<span class="string">"start per second inference benchmark "</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(iteration_time):</span><br><span class="line">                start = time.time()</span><br><span class="line">                val = sess.run(self.y_tensor, &#123;self.x_tensor: input_data&#125;)</span><br><span class="line">                times.append(time.time() - start)</span><br><span class="line">                <span class="keyword">if</span> (i%<span class="number">100</span> ==<span class="number">0</span>): </span><br><span class="line">                    print(times[i])</span><br><span class="line"></span><br><span class="line">                    imgs_per = (<span class="number">1</span>/times[i]) * self.batch_size</span><br><span class="line">                    print(<span class="string">"Iteration  %8.2f  / %8.2f    inference speed  %5.2f  imgs/sec,   Sec/batch time: %8.5f "</span> %(i , iteration_time, imgs_per, times[i]))</span><br><span class="line"></span><br><span class="line">                </span><br><span class="line">            print(<span class="string">"start per second inference benchmark "</span>)</span><br><span class="line">            imgs_per = (<span class="number">1</span>/np.mean(times)) * self.batch_size</span><br><span class="line"></span><br><span class="line">                    </span><br><span class="line">            print(<span class="string">"Benchmark inference the TFTRT Engine :  %8.2f  imgs/sec"</span> % (imgs_per))</span><br><span class="line">        <span class="keyword">return</span> times</span><br></pre></td></tr></table></figure>
<p>使用方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This line must be executed before loading Keras model.</span></span><br><span class="line">K.set_learning_phase(<span class="number">0</span>)</span><br><span class="line">model = load_model(<span class="string">'/dli/data/1217model_v2.h5'</span>)</span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">img_shape = (<span class="number">120</span>, <span class="number">120</span>, <span class="number">3</span>)</span><br><span class="line">input_data = np.random.randn(batch_size,<span class="number">120</span>, <span class="number">120</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">frozen_graph = FrozenGraph(model, img_shape)</span><br><span class="line"><span class="comment">#frozen_graph = FrozenGraph(prebuilt_graph_path, img_shape)</span></span><br><span class="line"><span class="keyword">del</span> model</span><br><span class="line"></span><br><span class="line">tf_engine = TfEngine(frozen_graph, batch_size)</span><br><span class="line">tf_times = tf_engine.time_graphdef(input_data,<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Average TF graph execution time: &#123;:0.5f&#125; s'</span>.format(np.mean(tf_times)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> tf_engine</span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line">trt_graph_def = TftrtEngine(frozen_graph, batch_size, <span class="string">'FP16'</span>)</span><br><span class="line"><span class="comment">#trt_graph_def = TftrtEngine(frozen_graph, batch_size, 'FP32')</span></span><br><span class="line">trt_times = trt_graph_def.time_graphdef(input_data,<span class="number">500</span>)</span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#tf_times = time_graphdef(tf_engine, input_data)</span></span><br><span class="line"><span class="comment">#trt_times = time_graphdef(trt_graph, input_data)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">"\n \n  Summary :  \n "</span>)</span><br><span class="line">print(<span class="string">'Average TF graph execution time: &#123;:0.5f&#125; s'</span>.format(np.mean(tf_times)))</span><br><span class="line">print(<span class="string">'Average TRT graph execution time: &#123;:0.5f&#125; s'</span>.format(np.mean(trt_times)))</span><br><span class="line">print(<span class="string">'Speedup factor: &#123;:0.2f&#125;'</span>.format(np.mean(tf_times) / np.mean(trt_times)))</span><br><span class="line"></span><br><span class="line"><span class="comment">#为将来的部署而保存引擎</span></span><br><span class="line">trt_graph_def.save_engine(<span class="string">'TF_TRT_FP16.engine'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="滑动窗口demo"><a href="#滑动窗口demo" class="headerlink" title="滑动窗口demo"></a>滑动窗口demo</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">MODEL_JOB_NUM = <span class="string">'##FIXME##'</span>  <span class="comment">## Remember to set this to be the job number for your model</span></span><br><span class="line">DATASET_JOB_NUM = <span class="string">'##FIXME##'</span>  <span class="comment">## Remember to set this to be the job number for your dataset</span></span><br><span class="line"></span><br><span class="line">MODEL_FILE = <span class="string">'/dli/data/digits/'</span> + MODEL_JOB_NUM + <span class="string">'/deploy.prototxt'</span>                 <span class="comment"># Do not change</span></span><br><span class="line">PRETRAINED = <span class="string">'/dli/data/digits/'</span> + MODEL_JOB_NUM + <span class="string">'/snapshot_iter_735.caffemodel'</span>    <span class="comment"># Do not change</span></span><br><span class="line">MEAN_IMAGE = <span class="string">'/dli/data/digits/'</span> + DATASET_JOB_NUM + <span class="string">'/mean.jpg'</span>                      <span class="comment"># Do not change</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load the mean image</span></span><br><span class="line">mean_image = caffe.io.load_image(MEAN_IMAGE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choose a random image to test against</span></span><br><span class="line"><span class="comment">#RANDOM_IMAGE = str(np.random.randint(10))</span></span><br><span class="line">IMAGE_FILE = <span class="string">'/dli/data/LouieReady.png'</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Tell Caffe to use the GPU</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"><span class="comment"># Initialize the Caffe model using the model trained in DIGITS</span></span><br><span class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</span><br><span class="line">                       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</span><br><span class="line">                       raw_scale=<span class="number">255</span>,</span><br><span class="line">                       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the input image into a numpy array and display it</span></span><br><span class="line">input_image = caffe.io.load_image(IMAGE_FILE)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate how many 256x256 grid squares are in the image</span></span><br><span class="line">rows = input_image.shape[<span class="number">0</span>]/<span class="number">256</span></span><br><span class="line">cols = input_image.shape[<span class="number">1</span>]/<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Subtract the mean image</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>] -= mean_image</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((rows,cols))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Iterate over each grid square using the model to make a class prediction</span></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        grid_square = input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># make prediction</span></span><br><span class="line">        prediction = net.predict([grid_square])</span><br><span class="line">        detections[i,j] = prediction[<span class="number">0</span>].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'Total inference time (sliding window without overlap): '</span> + str(end-start) + <span class="string">' seconds'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the amount of overlap between grid cells</span></span><br><span class="line">OVERLAP = <span class="number">0.25</span></span><br><span class="line">grid_rows = int((rows<span class="number">-1</span>)/(<span class="number">1</span>-OVERLAP))+<span class="number">1</span></span><br><span class="line">grid_cols = int((cols<span class="number">-1</span>)/(<span class="number">1</span>-OVERLAP))+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Image has %d*%d blocks of 256 pixels"</span> % (rows, cols)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"With overlap=%f grid_size=%d*%d"</span> % (OVERLAP, grid_rows, grid_cols)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((grid_rows,grid_cols))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over each grid square using the model to make a class prediction</span></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,grid_rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,grid_cols):</span><br><span class="line">        start_col = int(j*<span class="number">256</span>*(<span class="number">1</span>-OVERLAP))</span><br><span class="line">        start_row = int(i*<span class="number">256</span>*(<span class="number">1</span>-OVERLAP))</span><br><span class="line">        grid_square = input_image[start_row:start_row+<span class="number">256</span>, start_col:start_col+<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># make prediction</span></span><br><span class="line">        prediction = net.predict([grid_square])</span><br><span class="line">        detections[i,j] = prediction[<span class="number">0</span>].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Total inference time (sliding window with %f%% overlap: '</span> % (OVERLAP*<span class="number">100</span>)) + str(end-start) + <span class="string">' seconds'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># now with batched inference (one column at a time)</span></span><br><span class="line"><span class="comment"># we are not using a caffe.Classifier here so we need to do the pre-processing</span></span><br><span class="line"><span class="comment"># manually. The model was trained on random crops (256*256-&gt;227*227) so we</span></span><br><span class="line"><span class="comment"># need to do the cropping below. Similarly, we need to convert images</span></span><br><span class="line"><span class="comment"># from Numpy's Height*Width*Channel (HWC) format to Channel*Height*Width (CHW) </span></span><br><span class="line"><span class="comment"># Lastly, we need to swap channels from RGB to BGR</span></span><br><span class="line">net = caffe.Net(MODEL_FILE, PRETRAINED, caffe.TEST)</span><br><span class="line">start = time.time()</span><br><span class="line">net.blobs[<span class="string">'data'</span>].reshape(*[grid_cols, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((rows,cols))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        grid_square = input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># add to batch</span></span><br><span class="line">        grid_square = grid_square[<span class="number">14</span>:<span class="number">241</span>,<span class="number">14</span>:<span class="number">241</span>] <span class="comment"># 227*227 center crop        </span></span><br><span class="line">        image = np.copy(grid_square.transpose(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)) <span class="comment"># transpose from HWC to CHW</span></span><br><span class="line">        image = image * <span class="number">255</span> <span class="comment"># rescale</span></span><br><span class="line">        image = image[(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>), :, :] <span class="comment"># swap channels</span></span><br><span class="line">        net.blobs[<span class="string">'data'</span>].data[j] = image</span><br><span class="line">    <span class="comment"># make prediction</span></span><br><span class="line">    output = net.forward()[net.outputs[<span class="number">-1</span>]]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        detections[i,j] = output[j].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'Total inference time (batched inference): '</span> + str(end-start) + <span class="string">' seconds'</span></span><br></pre></td></tr></table></figure>
<h3 id="F1-Score计算demo"><a href="#F1-Score计算demo" class="headerlink" title="F1-Score计算demo"></a>F1-Score计算demo</h3><ul>
<li><strong>FP</strong>: False Positive（假阳性）</li>
<li><strong>TP</strong>: True Positive（真阳性）</li>
<li><strong>FN</strong>: False Negative （假阴性）</li>
<li><strong>TN</strong>: True Negative（真阴性）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the required modules/libraries.</span></span><br><span class="line"><span class="comment"># This should be a self-sufficient method.</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># function to calculate the correct threshold for the given data based on the given f1-score</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_threshold</span><span class="params">(predictions, ground_truth, f1_score)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return the proper threshold value</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param predictions:      An array of prediction scores</span></span><br><span class="line"><span class="string">                             </span></span><br><span class="line"><span class="string">                     </span></span><br><span class="line"><span class="string">    :param ground_truth:     And array of the same size as predeictions containing lables for of the dataset</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :f1_score:               The desired f1_score</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :return:                 The proper threshold value</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">        <span class="comment">#HINT* to find the right value, you may iterate the threshold value from 0.01 to 0.99 with 0.01 increments and calculate the f1 scores,</span></span><br><span class="line">    <span class="comment">#then check if the resulting f1_score matches the input f1_score and return the first matching value</span></span><br><span class="line">    </span><br><span class="line">    result = <span class="number">-0.01</span></span><br><span class="line">    </span><br><span class="line">    predicted_values= predictions.reshape(len(ground_truth))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#<span class="doctag">TODO:</span> create a list for for thresholds: [0.01, 0.02, ..., 0.99]  </span></span><br><span class="line">    threshold = [x/<span class="number">100</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> threshold: </span><br><span class="line">        </span><br><span class="line">        predicted_labels =(predicted_values &gt; value).astype(int)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># True Positives: Number of items with predicted labels of 1 and true labels of 1</span></span><br><span class="line">        TP = np.sum(((predicted_labels == <span class="number">1</span>) &amp; (ground_truth == <span class="number">1</span>)).astype(int) == <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># True Negatives: Number of items with predicted labels of 0 and true labels of 0</span></span><br><span class="line">        TN = np.sum(((predicted_labels == <span class="number">0</span>) &amp; (ground_truth == <span class="number">0</span>)).astype(int) == <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># False Positives: Number of items with predicted labels of 1 and true labels of 0</span></span><br><span class="line">        FP = np.sum(((predicted_labels == <span class="number">1</span>) &amp; (ground_truth == <span class="number">0</span>)).astype(int) == <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># False Negatives: Number of items with predicted labels of 0 and true labels of 1</span></span><br><span class="line">        FN = np.sum(((predicted_labels == <span class="number">0</span>) &amp; (ground_truth == <span class="number">1</span>)).astype(int) == <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># use the formulas provided in the course to calculate precision and recall</span></span><br><span class="line">        </span><br><span class="line">        precision = TP/(TP+FP)</span><br><span class="line">        recall = TP/(TP+FN)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># calculate the f1-score using the formula provided in the course</span></span><br><span class="line">        f1_score_calculated = round(<span class="number">2</span> * (precision * recall / (precision + recall) ),<span class="number">2</span>)</span><br><span class="line">        print(f1_score_calculated)</span><br><span class="line">        <span class="keyword">if</span> f1_score_calculated == f1_score:</span><br><span class="line">            result = value</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/11/04/英文自我介绍和PS/" rel="next" title="英文自我介绍和PS">
                <i class="fa fa-chevron-left"></i> 英文自我介绍和PS
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/11/26/C常用函数实现/" rel="prev" title="C常用函数实现">
                C常用函数实现 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="http://p3.ssl.cdn.btime.com/t015dde82f1bf46f58d.gif" alt="ZHIPENG">
            
              <p class="site-author-name" itemprop="name">ZHIPENG</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">71</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorRT的使用"><span class="nav-number">1.</span> <span class="nav-text">TensorRT的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#滑动窗口demo"><span class="nav-number">2.</span> <span class="nav-text">滑动窗口demo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#F1-Score计算demo"><span class="nav-number">3.</span> <span class="nav-text">F1-Score计算demo</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZHIPENG</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
